---
title: '[Kafka][1][初识Kafka]'
date: 2020-11-22 17:10:44
tags:
    - 大数据
    - Kafka
    - 消息队列
categories:
    - Kafka
---
## 第1章 初识Kafka



>参考资料
>
>- [Kafka权威指南](https://book.douban.com/subject/27665114/)



数据为企业的发展提供动力。我们从数据中获取信息，对它们进行分析处理，然后生成更多的数据。每个应用程序都会产生数据，包括日志消息、度量指标、用户活动记录、响应消息等。数据的点点滴滴都在暗示一些重要的事情，比如下一步行动的方向。



### 1.1 发布与订阅消息系统



先来了解发布与订阅消息系统的概念，并认识这个系统的重要性。

- 数据（消息）的**发送者**（发布者）**不会直接**把消息发送给**接收者**，这是发布与订阅消息系统的一个特点。
- 发布者以某种方式**对消息进行分类**，接收（订阅者）**订阅**它们，以便接收特定类型的消息。
- 发布与订阅系统一般会有一个**broker**，也就是发布消息的中心点。



#### 1.1.1 如何开始



发布与订阅消息系统的大部分**应用场景**都是从一个**简单**的**进程间通道**开始的。例如，你的应用需要往别处**发送度量指标(metric)**，可以在你的**应用**和另一个可以在**仪表盘应用**之间建立**直接连接**，然后通过这个连接推送度量指标，如下图所示。

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122152443.png)



但是这种方式在应对**复杂场景**时并不适合，如下图，如果场景变得复杂，**直连**会**让节点间的通信变得一团糟**

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122152645.png)



这时，技术债务开始凸显出来，于是你决定偿还掉一些。

- 你创建了一个**独立的应用**：用于**接收**来自其他应用程序的**度量指标**，并为其他应用提供一个**查询服务**。这样，之前架构的复杂度被降低到图1-3 所示的那样。
- 那么恭喜你，你已经创建了一个**基于发布与订阅**的**消息系统**。

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122152906.png)

#### 1.1.2　独立的队列系统



在你跟**度量指标**打得不可开交的时候，你的一个同事也正在跟**日志**消息奋战。还有另一个同事正在**跟踪网站用户的行为**，为负责机器学习开发的同事提供信息，同时为管理团队生成报告。你和同事们使用**相同的方式创建这些系统**，解耦信息的发布者和订阅者。

图1-4所示的架构包含了**3 个独立的** **发布与订阅系统**。

- **指标**(Metric)的发布订阅系统
- **日志**(logging)的发布订阅系统
- **用户跟踪**(tracking)的发布订阅系统

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122153146.png)



此时，你真正需要的是一个**单一**的**集中式系统**，它可以用来**发布和订阅** **多种通用类型的数据**，其规模可以随着公司业务的增长而增长。



### 1.2 Kafka登场



Kafka 就是为了**解决上述问题**而设计的一款**基于发布与订阅的消息系统**。

- 它一般被称为“**分布式提交日志**”或者“**分布式流平台**”。
- Kafka 中的数据是按照一定**顺序** **持久化**保存的，可以按需读取。
- 并且Kafka 的**数据** **分布在Kafka集群的各个部分**，具备数据**故障保护**和**性能伸缩**能力。



#### 1.2.1 消息和批次(Message and batch)



Kafka 的**数据单元**被称为**消息**。

- 消息由**字节数组**组成。
- 消息可以有一个**键**，键也是一个字节数组。可以**通过键**，**控制消息写入哪个分区**。最简单的例子就是为键生成一个散列值，然后使用散列值对主题分区数进行取模，为消息选取分区。这样可以保证具有相同键的消息总是被写到相同的分区上。



为了提高效率，消息被分**批次**写入Kafka。

- 批次就是**一组消息**，这些消息属于**同一个主题的同一分区**。
- 如果每一个消息都单独穿行于网络，会导致大量的网络开销，把消息分成批次传输可以**减少网络开销**。



#### 1.2.2 模式(schema)

对于Kafka 来说，消息不过是晦涩难懂的字节数组，所以有人建议用一些**额外的结构**来**定义消息内容含义**，让它们更易于理解，这就是**模式**。



Kafka 的开发者一般使用**Apache Avro**来**定义模式**

- 它最初是为Hadoop 开发的一款**序列化框架**。
- Avro 提供了一种紧凑的序列化格式，**模式**和**消息体**是**分开**的；
- 它还支持**强类型**和**模式进化**，其**版本**既向前**兼容**，也向后兼容。



#### 1.2.3 主题和分区(Topic and Partition)



Kafka 的消息通过**主题**进行分类。

- 主题就好比数据库的**表**，或者文件系统里的**文件夹**。
- **主题**可以被分为若干个**分区**，一个分区就是一个**提交日志(commit log)**。
- 消息以**追加**的方式写入分区，然后以**先入先出(FIFO)**的顺序**读取**。
- 要注意，由于一个主题一般包含几个分区，因此**无法在整个主题范围内**保证消息**有序**，但可以保证消息在**单个分区内** **有序**。
- Kafka 通过**分区**来实现**数据冗余(redundency)**和**伸缩性(scalability)**。
- 分区可以分布在不同的服务器上，也就是说，一个**主题**可以**横跨多个服务器**，以此来提供比单个服务器更强大的性能。



图1-5 所示的主题有4个分区，消息被追加写入每个分区的尾部。

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122155245.png)

#### 1.2.4 生产者和消费者



Kafka 系统的**用户**被分为**两种**：**生产者**和**消费者**



**生产者创建消息**。

- 一般情况下，一个消息会被发布到一个特定的**主题**上。
- 生产者在默认情况下把消息**均衡**地分布到**主题的所有分区**上，而并不关心特定消息会被写到哪个分区。
- 不过，在**某些情况下**，生产者也可以通过**分区器**和**键**，把消息直接**写到指定的分区**。



**消费者读取消息**。

- 消费者**订阅**一个或多个**主题**，并按照消息生成的**顺序读取**它们。
- 消费者通过检查消息的**偏移量**来区分已经读取过的消息。
- 偏移量是**消息的一种元数据**，它是一个不断**递增**的整数值，在创建每条消息时，Kafka 会把它附加到每条消息里。
- 消费者把每个分区**最后读取的消息**的**偏移量** **保存**在Zookeeper 或Kafka 上，如果消费者关闭或重启，它的**读取状态不会丢失**。



可以将多个消费者组织成一个**消费者群组**，来**共享**一个主题：

- **同一群组**的多个消费者共同**读取一个主题**。
- 群组保证**每个分区**只能被**一个消费者**使用，并且整个群组对于**主题中的每条消息**精确**处理一次**。
- 消费者与分区之间的**映射**通常被称为消费者对分区的**所有权关系**。



图1-6 所示的群组中，有3 个消费者同时读取一个主题。其中的两个消费者各自读取一个分区，另外一个消费者读取其他两个分区。

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122161046.png)



#### 1.2.5 broker和集群



一个独立的Kafka 服务器被称为**broker**。

- broker **接收**来自**生产者**的消息，为消息设置偏移量，并提交消息到**磁盘保存**。
- broker 为**消费者**提供服务，对读取分区的请求作出**响应**，返回已经提交到磁盘上的消息。



多个broker可以组成一个Kafka**集群**

- 每个集群都有一个broker 同时充当了**集群控制器**的角色。控制器负责管理集群，包括将**分区分配**给broker 和**监控**broker。
- 在集群中，**每个分区**都对应一个**首领broker**，该broker 被称为分区的首领。
- 并且**一个分区**可以分配给**多个broker**，但只有一个首领。其他broker都是这个首领的**从者broker**。这个时候会发生**分区复制**。首领broker会复制消息到从者broker。这种复制机制为分区提供了**消息冗余**
- 这样，如果**首领broker 失效**，从者broker可以**接管**领导权，而服务不会停止且消息不会丢失

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122161736.png)



**保留消息**（在一定期限内）是Kafka 的一个重要特性。Kafka broker 默认的消息保留策略是这样的：

- 要么保留一段时间（比如7 天），
- 要么保留到消息达到一定大小的字节数（比如1GB）。



#### 1.2.6 多集群



kafka也支持**多集群**。如下图

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122161957.png)

多集群具体介绍略，后面章节会提到。



### 1.3 为什么选择Kafka



有很多其他的发布/订阅消息传递系统，例如：RabbitMQ、ActiveMQ等，那么是什么让Apache Kafka成为一个好的选择呢？



#### 1.3.1 多个生产者



卡夫卡能够无缝地支持**多个生产者**，无论这些生产者使用的是多个主题还是同一主题。这使得该系统非常适合**聚合**来自许多前端系统的数据，并使其保持一致。



#### 1.3.2 多个消费者



Kafka 也支持**多个消费者**从**同一个消息流**上读取数据，而且消费者之间**互不影响**。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。



另外，多个消费者可以组成一个**消费者群组**，它们**共享**一个消息流，并保证**整个群组**对**每条消息**只处理**一次**。



#### 1.3.3 基于磁盘的数据存储



Kafka允许**消费者** **非实时**地读取消息，这要归功于Kafka 的**消息保留**特性。

- 消费者可能会因为**自身处理能力低**或突发的**流量高峰**导致**无法及时**读取消息

- 而**持久化数据**可以**保证数据不会丢失**。
  - 消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端。
  - 消费者可以被关闭，但消息会继续保留在Kafka 里。消费者可以从上次中断的地方继续处理消息。



#### 1.3.4 伸缩性



Kafka可以通过**增加broker**的方式来实现**横向扩展**，它的**伸缩性**很灵活



>例如：用户在开发阶段可以先使用单个broker，再扩展到包含3 个broker 的小型开发集群，然后随着数据量不断增长，部署到生产环境的集群可能包含上百个broker。



#### 1.3.5 高性能



上面提到的所有特性，让Kafka 成为了一个高性能的发布与订阅消息系统。通过横向扩展生产者、消费者和broker，Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时，它还能保证**亚秒级的消息延迟**。



### 1.4 Kafka在数据生态系统中的重要性



在现代应用场景中，数据分布在很多不同的应用。这些应用可以整体上看作一个数据生态系统。



Kafka 为数据生态系统带来了**循环系统**，如图1-9 所示。

- 它负责各个应用间的**消息传递**，为所有应用提供**一致的接口**。
- 生产者应用和消费者应用之间不再有紧密的**耦合**，也不需要在它们之间建立任何类型的**直连**。
- 我们可以根据业务需要**添加或移除应用**，因为生产者不再关心谁在使用数据，也不关心有多少个消费者。

![](https://healthlung.oss-cn-beijing.aliyuncs.com/20201122163514.png)



### 1.5 使用场景



#### 1.5.1 活动跟踪(Activity tracking)



Kafka 最初的使用场景是**跟踪用户的活动**。

- 网站用户与前端应用程序发生交互，前端应用程序生成**用户活动相关的消息**。这些消息比如页面访问次数和点击量。
- 这些消息可以被**发布到Kafka**的一个或多个主题上，然后由一个或多个**后端应用程序负责读取**。这样，我们就可以用它们来**生成报告**，为**机器学习**系统提供数据，**更新搜索结果**等等。



#### 1.5.2 发送通知(Messaging)



Kafka 的另一个基本用途是**发送通知**。

- **应用程序向用户发送通知**（比如**邮件**）就是通过传递消息来实现的。
- 这些应用程序组件可以**直接**生成消息并**发布到kafka**，而不需要关心消息是如何发送给用户的，也不需要关心这些消息发送给用户时是什么格式的。
- 另一个**公共应用程序**会从Kakfa**读取**这些消息，并且**处理**消息成适合用户阅读的格式，然后**发送**给用户



#### 1.5.3 度量指标和日志记录(Metric and logging)



Kafka 也可以用于收集应用程序和系统度量指标以及日志。

- 多个不同的应用程序定期把**度量指标**发布到Kafka 主题上，监控系统读取并分析这些消息。
- **日志消息**也可以被发布到Kafka 主题上，然专门的日志搜索系统（比如Elasticsearch）或安全分析应用程序会读取并处理它们。



#### 1.5.4 提交日志(Commit log)



**Kafka 的基本概念来源于数据库的提交日志**，所以使用Kafka 作为提交日志是件顺理成章的事。我们可以把数据库的更新放到Kafka 上，应用程序可以读取这些更新。

- 例如：数据库主库和从库之间的**更新复制**
- 或者**合并**多个数据库的**更新**到一个数据库实例上



#### 1.5.5 流处理(Streaming processing)



用户可以编写小型应用程序来操作Kafka 消息，比如计算度量指标，为其他应用程序有效地处理消息分区，或者对来自多个数据源的消息进行转换。



### 1.6 起源故事



#### 1.6.1LinkedIn的问题



LinkedIn 有一个**指标监控系统**。LinkedIn 还有一个比较复杂的**请求跟踪系统**。与此同时，还创建了另一个用于**收集用户活动信息的系统**。这些系统都需要从多个前端获取数据，这时就需要一个**统一且通用的发布订阅系统**。



#### 1.6.2 Kafka的诞生

LinkedIn 的开发团队由Jay Kreps 领导。Jay Kreps 是LinkedIn 的首席工程师，之前负责分布式键值存储系统Voldemort 的开发。初建团队成员还包括Neha Narkhede，不久之后，Jun Rao 也加入了进来。他们一起着手创建一个消息系统，可以同时满足上述的两种需求，并且可以在未来进行横向扩展。他们的主要目标如下：

- 使用**推送和拉取**模型**解耦生产者和消费者**；
- 为消息传递系统中的消息提供**数据持久化**，以便支持**多个消费者**；
- 通过系统优化实现**高吞吐量**；
- 系统可以随着数据流的增长进行**横向扩展**。



最后我们看到的这个发布与订阅消息系统具有**典型的消息系统接口**，但从**存储层**来看，它**更像是一个日志聚合系统**。Kafka 使用**Avro** 作为消息序列化框架，每天高效地处理数十亿级别的度量指标和用户活动跟踪信息。LinkedIn 已经拥有超过万亿级别的消息使用量（截止到2015 年8 月），而且每天仍然需要处理超过千万亿字节的数据。



#### 1.6.3 走向开源



略



#### 1.6.4 命名



>我想既然Kafka 是为了写数据而产生的，那么用作家的名字来命名会显得更有意义。我在大学时期上过很多文学课程，很喜欢Franz Kafka。况且，对于开源项目来说，这个名字听起来很酷。因此，名字和应用本身基本没有太多联系。-------Jay Kreps